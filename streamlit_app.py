import streamlit as st
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
from datetime import datetime
import os

def crawl_naver_powerlink(keywords):
    options = webdriver.ChromeOptions()
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--headless")  # streamlitìš© headless ëª¨ë“œ

    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)

    data = []

    for keyword in keywords:
        driver.get("https://www.naver.com")

        try:
            search_box = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.NAME, "query"))
            )
            search_box.send_keys(keyword)
            search_box.send_keys(Keys.RETURN)

            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "nad_area"))
            )
        except:
            data.append([keyword, "ì—†ìŒ", ""])
            continue

        page_source = driver.page_source
        soup = BeautifulSoup(page_source, "html.parser")
        powerlinks = soup.select(".nad_area .lst_type > li")

        if not powerlinks:
            data.append([keyword, "ì—†ìŒ", ""])
        else:
            for ad in powerlinks:
                title_element = ad.select_one("a.site")
                title = title_element.get_text(strip=True) if title_element else "ì œëª© ì—†ìŒ"

                link_element = ad.select_one("a.lnk_url")
                if link_element:
                    onclick_attr = link_element.get("onclick", "")
                    match = re.search(r"urlencode\('(.+?)'\)", onclick_attr)
                    link = match.group(1) if match else "ë§í¬ ì—†ìŒ"
                else:
                    link = "ë§í¬ ì—†ìŒ"

                data.append([keyword, title, link])

    driver.quit()

    if data:
        df = pd.DataFrame(data, columns=["ê²€ìƒ‰ í‚¤ì›Œë“œ", "ê´‘ê³  ì œëª©", "ê´‘ê³  ë§í¬"])
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        filename = f"naver_powerlink_{timestamp}.xlsx"
        df.to_excel(filename, index=False, engine='openpyxl')
        return df, filename
    else:
        return None, None


# Streamlit UI êµ¬ì„±
st.title("ë„¤ì´ë²„ íŒŒì›Œë§í¬ ê´‘ê³  í¬ë¡¤ëŸ¬")
st.markdown("ë„¤ì´ë²„ ê²€ìƒ‰ê²°ê³¼ì˜ íŒŒì›Œë§í¬ ê´‘ê³  ì œëª©ê³¼ ë§í¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")

keywords_input = st.text_area("ğŸ” í¬ë¡¤ë§í•  í‚¤ì›Œë“œ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)", height=200)
if st.button("í¬ë¡¤ë§ ì‹œì‘"):
    if not keywords_input.strip():
        st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        keywords = [kw.strip() for kw in keywords_input.strip().split("\n") if kw.strip()]
        with st.spinner("í¬ë¡¤ë§ ì¤‘... ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ ì—´ë¦¬ê³  ì¢…ë£Œë©ë‹ˆë‹¤."):
            result_df, filename = crawl_naver_powerlink(keywords)

        if result_df is not None:
            st.success(f"í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(result_df)}ê±´ ìˆ˜ì§‘.")
            st.dataframe(result_df)

            with open(filename, "rb") as f:
                st.download_button(
                    label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=f,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

            os.remove(filename)
        else:
            st.error("í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
