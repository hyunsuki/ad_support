import requests
from bs4 import BeautifulSoup
import pandas as pd
import streamlit as st
from io import BytesIO
import re

def crawl_naver_powerlink_with_requests(keywords):
    data = []

    for keyword in keywords:
        query = requests.utils.quote(keyword)

        # ğŸ“Œ PC ë²„ì „ í¬ë¡¤ë§
        url_pc = f"https://search.naver.com/search.naver?query={query}"
        response_pc = requests.get(url_pc)
        soup_pc = BeautifulSoup(response_pc.text, "html.parser")

        powerlink_area_pc = soup_pc.select_one(".nad_area")
        if powerlink_area_pc:
            powerlinks_pc = powerlink_area_pc.select(".lst_type li")
            if powerlinks_pc:
                for ad in powerlinks_pc:
                    title_element = ad.select_one("a.site")
                    title = title_element.text.strip() if title_element else "ì—†ìŒ"

                    link_element = ad.select_one("a.lnk_url")
                    link = link_element.text.strip() if link_element else ""

                    data.append([keyword, title, link, "PC"])
            else:
                data.append([keyword, "ì—†ìŒ", "", "PC"])
        else:
            data.append([keyword, "ì—†ìŒ", "", "PC"])

        # ğŸ“Œ ëª¨ë°”ì¼ ë²„ì „ í¬ë¡¤ë§
        headers_mo = {
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) "
                          "AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 "
                          "Mobile/15E148 Safari/604.1"
        }
        url_mo = f"https://m.search.naver.com/search.naver?query={query}"
        response_mo = requests.get(url_mo, headers=headers_mo)
        soup_mo = BeautifulSoup(response_mo.text, "html.parser")

        powerlinks_mo = soup_mo.select("#contentsList li")
        if powerlinks_mo:
            for ad in powerlinks_mo:
                title_element = ad.select_one(".tit_area .tit")
                title = title_element.text.strip() if title_element else "ì—†ìŒ"

                link_element = ad.select_one(".url_area .url_link")
                link = link_element.text.strip() if link_element else ""

                data.append([keyword, title, link, "MO"])
        else:
            data.append([keyword, "ì—†ìŒ", "", "MO"])

    return data

# ğŸ“Œ Streamlit ì•± UI
st.title("ë„¤ì´ë²„ íŒŒì›Œë§í¬ ê´‘ê³  í¬ë¡¤ëŸ¬")
st.write("ë„¤ì´ë²„ ê²€ìƒ‰ì—ì„œ íŒŒì›Œë§í¬ ê´‘ê³ ë¥¼ í¬ë¡¤ë§í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

keywords_input = st.text_area("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì—¬ëŸ¬ í‚¤ì›Œë“œëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)", "")
keywords = keywords_input.split("\n") if keywords_input else []

if st.button("í¬ë¡¤ë§ ì‹œì‘"):
    if keywords:
        with st.spinner("í¬ë¡¤ë§ ì¤‘..."):
            results = crawl_naver_powerlink_with_requests(keywords)

        if results:
            st.write("í¬ë¡¤ë§ëœ ê²°ê³¼:")
            df = pd.DataFrame(results, columns=["ê²€ìƒ‰ í‚¤ì›Œë“œ", "ê´‘ê³  ì œëª©", "í‘œì‹œìš© ë§í¬", "êµ¬ë¶„"])
            
            # ì¤‘ë³µ ì œê±° (ê´‘ê³  ì œëª©+ë§í¬ ê¸°ì¤€)
            df = df.drop_duplicates(subset=["ê²€ìƒ‰ í‚¤ì›Œë“œ", "ê´‘ê³  ì œëª©", "í‘œì‹œìš© ë§í¬", "êµ¬ë¶„"])

            st.dataframe(df)

            output = BytesIO()
            df.to_excel(output, index=False)
            output.seek(0)

            st.download_button(
                label="ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=output,
                file_name="naver_powerlink_requests.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    else:
        st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
