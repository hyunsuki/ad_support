import requests
from bs4 import BeautifulSoup
import pandas as pd
import streamlit as st
from io import BytesIO
import time

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëª¨ë°”ì¼ìš© Selenium ë“œë¼ì´ë²„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_mobile_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=375,812")
    options.add_argument(
        "user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) "
        "AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1"
    )
    service = Service("/usr/bin/chromedriver")  # í™˜ê²½ì— ë”°ë¼ ê²½ë¡œ ìˆ˜ì •
    return webdriver.Chrome(service=service, options=options)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ í¬ë¡¤ëŸ¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def crawl_naver_powerlink(keywords):
    data = []
    headers_pc_ad = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
        )
    }

    mobile_driver = get_mobile_driver()

    for keyword in keywords:
        q = requests.utils.quote(keyword)

        # â”€â”€â”€ PC ê´‘ê³  (ad.search.naver.com ë„ë©”ì¸)
        url_pc_ad = f"https://ad.search.naver.com/search.naver?where=ad&query={q}"
        res_pc_ad = requests.get(url_pc_ad, headers=headers_pc_ad)
        soup_pc_ad = BeautifulSoup(res_pc_ad.text, "html.parser")

        # ê´‘ê³  ì œëª©: a.lnk_tit, í‘œì‹œë§í¬: a.lnk_url
        #titles_pc = soup_pc_ad.select("a.lnk_tit")
        titles_pc = soup_pc_ad.select("a.site")
        links_pc  = soup_pc_ad.select("a.lnk_url")

        if titles_pc and links_pc:
            for t, l in zip(titles_pc, links_pc):
                title = t.get_text(strip=True)
                link  = l.get_text(strip=True)
                data.append([keyword, title, link, "PC"])
        else:
            data.append([keyword, "ì—†ìŒ", "", "PC"])


        # â”€â”€â”€ ëª¨ë°”ì¼ ê´‘ê³  (ì›ë˜ëŒ€ë¡œ Selenium)
        url_mo = f"https://m.ad.search.naver.com/search.naver?where=m_expd&query={q}&referenceId"
        mobile_driver.get(url_mo)

        # 1) ìŠ¤í¬ë¡¤
        for _ in range(3):
            mobile_driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)

        # 2) â€œê´‘ê³  ë”ë³´ê¸°â€ í´ë¦­
        try:
            btn = mobile_driver.find_element(By.LINK_TEXT, "ê´‘ê³  ë”ë³´ê¸°")
            btn.click()
            time.sleep(1)
        except:
            pass

        # 3) ì¶”ê°€ ìŠ¤í¬ë¡¤
        mobile_driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1)

        # 4) ê´‘ê³  ìˆ˜ì§‘
        try:
            WebDriverWait(mobile_driver, 10).until(
                EC.presence_of_all_elements_located(
                    (By.CSS_SELECTOR, "ul#contentsList.powerlink_list li.list_item")
                )
            )
            ads_mo = mobile_driver.find_elements(
                By.CSS_SELECTOR, "ul#contentsList.powerlink_list li.list_item"
            )
            if not ads_mo:
                raise Exception("ê´‘ê³  ì—†ìŒ")
            for ad in ads_mo:
                title = ad.find_element(By.CSS_SELECTOR, ".site").text
                try:
                    link = ad.find_element(By.CSS_SELECTOR, ".url_link").text
                except:
                    link = ad.find_element(By.CSS_SELECTOR, ".url").text
                data.append([keyword, title, link, "MO"])
        except:
            data.append([keyword, "ì—†ìŒ", "", "MO"])

    mobile_driver.quit()
    return data

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸŸ¢ ë„¤ì´ë²„ íŒŒì›Œë§í¬ ê´‘ê³  í¬ë¡¤ëŸ¬")
st.write("PC/ëª¨ë°”ì¼ íŒŒì›Œë§í¬ ê´‘ê³ ë¥¼ í¬ë¡¤ë§í•˜ê³  ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")

keywords_input = st.text_area("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥ (ì¤„ë°”ê¿ˆ êµ¬ë¶„)", "")
keywords = [k.strip() for k in keywords_input.split("\n") if k.strip()]

if st.button("í¬ë¡¤ë§ ì‹œì‘"):
    if not keywords:
        st.warning("â— í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        with st.spinner("â³ í¬ë¡¤ë§ ì¤‘..."):
            results = crawl_naver_powerlink(keywords)

        df = pd.DataFrame(
            results,
            columns=["ê²€ìƒ‰ í‚¤ì›Œë“œ", "ê´‘ê³ ì£¼/ì œëª©", "í‘œì‹œìš© ë§í¬", "êµ¬ë¶„"]
        )
        st.success("âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
        st.dataframe(df)

        buf = BytesIO()
        df.to_excel(buf, index=False, engine="openpyxl")
        buf.seek(0)
        st.download_button(
            "ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=buf,
            file_name="naver_powerlink_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
